<div align="center">
    <img align="center" src="https://github-readme-stats.vercel.app/api?username=idocx&show_icons=true&count_private=true&hide_border=true" alt="idocx's Github Stats"></img>
</div>

---

**Yuxing** believes firmly in the saying "With four parameters I can fit an elephant, and with five I can make him wiggle his trunk" by Enrico Fermi. <sup>[1]</sup> So, he devotes his entire though short research career to tuning five hypermeters of a model and is convinced that he will finally make it outperform any SOTA models like GPT-3 and AlphaFold 2.

Yuxing is not a computer scientist, a physicist or a chemist, but a *HYPERPARAMETER TUNING SCIENTIST*. "That makes a lot of difference. Hyperparameter tuning is the technique that changes our life, especially before pulishing a paper.", he said.

[1] Dyson, F. A meeting with Enrico Fermi. Nature 427, 297 (2004).


---

### ðŸ“Š Weekly development time
<!--START_SECTION:waka-->

```txt
From: 01 January 2026 - To: 08 January 2026

Python   3 hrs 37 mins   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–’â–‘â–‘â–‘â–‘   81.15 %
Other    50 mins         â–ˆâ–ˆâ–ˆâ–ˆâ–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   18.69 %
JSON     0 secs          â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   00.14 %
Text     0 secs          â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   00.02 %
```

<!--END_SECTION:waka-->

### 

![Visitor Badge](https://visitor-badge.laobi.icu/badge?page_id=idocx.idocx)